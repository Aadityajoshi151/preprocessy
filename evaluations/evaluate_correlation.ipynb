{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access preprocessy module. Required in .ipynb files\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.datasets import load_iris, load_boston, load_breast_cancer, load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, r2_score\n",
    "from preprocessy.feature_selection import Correlation, SelectKBest\n",
    "from preprocessy.resampling import Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to print the correlation statistics for the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(X, threshold=0.8):\n",
    "    corr = Correlation()\n",
    "    for col1, col2, value, sign in corr.find(X,threshold):\n",
    "        print(f'{col1} x {col2}\\nCorrelation - {value:.2f}\\nType - {sign}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Dataset\n",
    "\n",
    "The Breast Cancer dataset comprises of `569 records` and `30 features`. Some these features are highly correlated to each other. First we will list down a few of those correlations with `values > 0.97`. The goal is to compare the results before and after dropping the highly correlated columns indicated by the `Correlation` class from `preprocessy.feature_selection` module and keeping all the other preprocessing thresholds the same. We will compare the accuracy and time taken to get the results. We use `Split` class from `preprocessy.resampling` module to perform the train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset - Breast Cancer\n",
      "mean radius x mean perimeter\n",
      "Correlation - 1.00\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n",
      "mean radius x mean area\n",
      "Correlation - 0.99\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n",
      "mean perimeter x mean area\n",
      "Correlation - 0.99\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n",
      "mean perimeter x worst perimeter\n",
      "Correlation - 0.97\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n",
      "radius error x perimeter error\n",
      "Correlation - 0.97\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n",
      "worst radius x worst perimeter\n",
      "Correlation - 0.99\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n",
      "worst radius x worst area\n",
      "Correlation - 0.98\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n",
      "worst perimeter x worst area\n",
      "Correlation - 0.98\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset - Breast Cancer\")\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "eval(X,threshold=0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model directly\n",
    "\n",
    "We now train a random forest classifier on the dataset without dropping any correlated columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - 1.0\n",
      "Time taken - 0.208392\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = RandomForestClassifier()\n",
    "X_train, X_test, y_train, y_test = Split().train_test_split(X, y, test_size=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy_1 = classification_report(y_test,preds,output_dict=True)[\"accuracy\"]\n",
    "print(f'Accuracy - {accuracy_1}')\n",
    "print(f'Time taken - {(time.time()-start):4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model post preprocessing\n",
    "\n",
    "We now drop some of the columns that are correlated with `mean radius`, `worst radius` and `radius error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['mean area','mean perimeter','worst area','worst perimeter','perimeter error','area error'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - 1.0\n",
      "Time taken - 0.192731\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = RandomForestClassifier()\n",
    "X_train, X_test, y_train, y_test = Split().train_test_split(X, y, test_size=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy_2 = classification_report(y_test,preds,output_dict=True)[\"accuracy\"]\n",
    "print(f'Accuracy - {accuracy_2}')\n",
    "print(f'Time taken - {(time.time()-start):4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "For this particular dataset and thresholds, the accuracy of both approaches is `100%` but the time consumed after dropping the correlated columns is slightly less than without dropping them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset\n",
    "\n",
    "The iris dataset consists of `150 records` and `4 features`. As the number of features is less, removing correlated columns will not be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset - Iris\")\n",
    "X,y = load_iris(return_X_y=True,as_frame=True)\n",
    "eval(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Dataset\n",
    "\n",
    "The boston housing dataset consists of `506 records` and `13 features`. We will apply the same comparison test as before but with a threshold of 0.7 this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset - Boston\n",
      "INDUS x NOX\n",
      "Correlation - 0.76\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n",
      "INDUS x DIS\n",
      "Correlation - -0.71\n",
      "Type - Negative Correlation\n",
      "\n",
      "\n",
      "INDUS x TAX\n",
      "Correlation - 0.72\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n",
      "NOX x AGE\n",
      "Correlation - 0.73\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n",
      "NOX x DIS\n",
      "Correlation - -0.77\n",
      "Type - Negative Correlation\n",
      "\n",
      "\n",
      "AGE x DIS\n",
      "Correlation - -0.75\n",
      "Type - Negative Correlation\n",
      "\n",
      "\n",
      "RAD x TAX\n",
      "Correlation - 0.91\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset - Boston\")\n",
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = pd.Series(dataset.target, name=\"Target\")\n",
    "eval(X,threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model directly\n",
    "\n",
    "We now train a linear regression model on the dataset without dropping any correlated columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - 0.6891093866231174\n",
      "Time taken - 0.011102\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = LinearRegression(fit_intercept=True, normalize=True, copy_X=True)\n",
    "X_train, X_test, y_train, y_test = Split().train_test_split(X, y)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy_1 = r2_score(y_test, preds)\n",
    "print(f'Accuracy - {accuracy_1}')\n",
    "print(f'Time taken - {(time.time()-start):4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model post preprocessing\n",
    "\n",
    "We now drop some of the columns that are correlated with `TAX`, `NOX` and `DIS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['TAX','NOX','DIS'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - 0.6933951730354478\n",
      "Time taken - 0.010524\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = LinearRegression(fit_intercept=True, normalize=True, copy_X=True)\n",
    "X_train, X_test, y_train, y_test = Split().train_test_split(X, y)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy_2 = r2_score(y_test, preds)\n",
    "print(f'Accuracy - {accuracy_2}')\n",
    "print(f'Time taken - {(time.time()-start):4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "For this particular dataset and thresholds, the accuracy improves slightly after dropping the correlated columns and the time consumed is slightly less than without dropping them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Dataset\n",
    "\n",
    "The boston housing dataset consists of `442 records` and `10 features`. We will apply the same comparison test as before but with a threshold of 0.7 this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset - Diabetes\n",
      "s1 x s2\n",
      "Correlation - 0.90\n",
      "Type - Positive Correlation\n",
      "\n",
      "\n",
      "s3 x s4\n",
      "Correlation - -0.74\n",
      "Type - Negative Correlation\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset - Diabetes\")\n",
    "X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "eval(X,threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model directly\n",
    "\n",
    "We now train a linear regression model on the dataset without dropping any correlated columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - 0.5065368093248677\n",
      "Time taken - 0.009568\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = LinearRegression(fit_intercept=True, normalize=True, copy_X=True)\n",
    "X_train, X_test, y_train, y_test = Split().train_test_split(X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy_1 = r2_score(y_test, preds)\n",
    "print(f'Accuracy - {accuracy_1}')\n",
    "print(f'Time taken - {(time.time()-start):4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model post preprocessing\n",
    "\n",
    "We now drop `s2` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['s2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - 0.5055602962093787\n",
      "Time taken - 0.009409\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = LinearRegression(fit_intercept=True, normalize=True, copy_X=True)\n",
    "X_train, X_test, y_train, y_test = Split().train_test_split(X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy_1 = r2_score(y_test, preds)\n",
    "print(f'Accuracy - {accuracy_1}')\n",
    "print(f'Time taken - {(time.time()-start):4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "For this particular dataset and thresholds, the accuracy decreases slightly after dropping the correlated columns and the time consumed is slightly less than without dropping them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
